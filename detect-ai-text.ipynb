{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":61542,"databundleVersionId":6888007,"sourceType":"competition"},{"sourceId":6865136,"sourceType":"datasetVersion","datasetId":3945154},{"sourceId":6890527,"sourceType":"datasetVersion","datasetId":3942644},{"sourceId":6901341,"sourceType":"datasetVersion","datasetId":3960967},{"sourceId":6977472,"sourceType":"datasetVersion","datasetId":4005256}],"dockerImageVersionId":30626,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-01-07T13:29:56.738417Z","iopub.execute_input":"2024-01-07T13:29:56.73887Z","iopub.status.idle":"2024-01-07T13:29:58.473359Z","shell.execute_reply.started":"2024-01-07T13:29:56.738825Z","shell.execute_reply":"2024-01-07T13:29:58.472079Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import sys\nimport gc\n\nimport pandas as pd\nfrom sklearn.model_selection import StratifiedKFold\nimport numpy as np\nfrom sklearn.metrics import roc_auc_score\nimport numpy as np\nfrom lightgbm import LGBMClassifier\nfrom catboost import CatBoostClassifier\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\nfrom tokenizers import (\n    decoders,\n    models,\n    normalizers,\n    pre_tokenizers,\n    processors,\n    trainers,\n    Tokenizer,\n)\n\nfrom datasets import Dataset\nfrom tqdm.auto import tqdm\nfrom transformers import PreTrainedTokenizerFast\n\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.ensemble import VotingClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier, VotingClassifier\nimport optuna","metadata":{"execution":{"iopub.status.busy":"2024-01-07T13:29:58.476048Z","iopub.execute_input":"2024-01-07T13:29:58.476571Z","iopub.status.idle":"2024-01-07T13:30:11.172992Z","shell.execute_reply.started":"2024-01-07T13:29:58.476535Z","shell.execute_reply":"2024-01-07T13:30:11.171825Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = pd.read_csv('/kaggle/input/llm-detect-ai-generated-text/test_essays.csv')\nsub = pd.read_csv('/kaggle/input/llm-detect-ai-generated-text/sample_submission.csv')\norg_train = pd.read_csv('/kaggle/input/llm-detect-ai-generated-text/train_essays.csv')\ntrain = pd.read_csv(\"/kaggle/input/daigt-v2-train-dataset/train_v2_drcat_02.csv\", sep=',')","metadata":{"execution":{"iopub.status.busy":"2024-01-07T13:30:11.174605Z","iopub.execute_input":"2024-01-07T13:30:11.17557Z","iopub.status.idle":"2024-01-07T13:30:13.553121Z","shell.execute_reply.started":"2024-01-07T13:30:11.175534Z","shell.execute_reply":"2024-01-07T13:30:13.551778Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = train.drop_duplicates(subset=['text'])\ntrain.reset_index(drop=True, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2024-01-07T13:30:13.555676Z","iopub.execute_input":"2024-01-07T13:30:13.556119Z","iopub.status.idle":"2024-01-07T13:30:13.656027Z","shell.execute_reply.started":"2024-01-07T13:30:13.556085Z","shell.execute_reply":"2024-01-07T13:30:13.654504Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"LOWERCASE = False\nVOCAB_SIZE = 30522","metadata":{"execution":{"iopub.status.busy":"2024-01-07T13:30:13.658231Z","iopub.execute_input":"2024-01-07T13:30:13.658838Z","iopub.status.idle":"2024-01-07T13:30:13.666409Z","shell.execute_reply.started":"2024-01-07T13:30:13.658787Z","shell.execute_reply":"2024-01-07T13:30:13.664584Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Creating Byte-Pair Encoding tokenizer\nraw_tokenizer = Tokenizer(models.BPE(unk_token=\"[UNK]\"))\nraw_tokenizer.normalizer = normalizers.Sequence([normalizers.NFC()] + [normalizers.Lowercase()] if LOWERCASE else [])\nraw_tokenizer.pre_tokenizer = pre_tokenizers.ByteLevel()\nspecial_tokens = [\"[UNK]\", \"[PAD]\", \"[CLS]\", \"[SEP]\", \"[MASK]\"]\ntrainer = trainers.BpeTrainer(vocab_size=VOCAB_SIZE, special_tokens=special_tokens)\ndataset = Dataset.from_pandas(test[['text']])\ndef train_corp_iter(): \n    for i in range(0, len(dataset), 1000):\n        yield dataset[i : i + 1000][\"text\"]\nraw_tokenizer.train_from_iterator(train_corp_iter(), trainer=trainer)\ntokenizer = PreTrainedTokenizerFast(\n    tokenizer_object=raw_tokenizer,\n    unk_token=\"[UNK]\",\n    pad_token=\"[PAD]\",\n    cls_token=\"[CLS]\",\n    sep_token=\"[SEP]\",\n    mask_token=\"[MASK]\",\n)\ntokenized_texts_test = []\n\nfor text in tqdm(test['text'].tolist()):\n    tokenized_texts_test.append(tokenizer.tokenize(text))\n\ntokenized_texts_train = []\n\nfor text in tqdm(train['text'].tolist()):\n    tokenized_texts_train.append(tokenizer.tokenize(text))","metadata":{"execution":{"iopub.status.busy":"2024-01-07T13:30:13.668079Z","iopub.execute_input":"2024-01-07T13:30:13.668504Z","iopub.status.idle":"2024-01-07T13:33:22.964106Z","shell.execute_reply.started":"2024-01-07T13:30:13.668469Z","shell.execute_reply":"2024-01-07T13:33:22.959571Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def dummy(text):\n    return text\nvectorizer = TfidfVectorizer(ngram_range=(3, 5), lowercase=False, sublinear_tf=True, analyzer = 'word',\n    tokenizer = dummy,\n    preprocessor = dummy,\n    token_pattern = None, strip_accents='unicode')\n\nvectorizer.fit(tokenized_texts_test)\n\n# Getting vocab\nvocab = vectorizer.vocabulary_\n\nprint(vocab)\n\nvectorizer = TfidfVectorizer(ngram_range=(3, 5), lowercase=False, sublinear_tf=True, vocabulary=vocab,\n                            analyzer = 'word',\n                            tokenizer = dummy,\n                            preprocessor = dummy,\n                            token_pattern = None, strip_accents='unicode'\n                            )\n\ntf_train = vectorizer.fit_transform(tokenized_texts_train)\ntf_test = vectorizer.transform(tokenized_texts_test)\n\ndel vectorizer\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2024-01-07T13:33:22.972068Z","iopub.execute_input":"2024-01-07T13:33:22.973514Z","iopub.status.idle":"2024-01-07T13:38:47.199256Z","shell.execute_reply.started":"2024-01-07T13:33:22.973454Z","shell.execute_reply":"2024-01-07T13:38:47.197932Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train = train['label'].values","metadata":{"execution":{"iopub.status.busy":"2024-01-07T13:38:47.200743Z","iopub.execute_input":"2024-01-07T13:38:47.201137Z","iopub.status.idle":"2024-01-07T13:38:47.206472Z","shell.execute_reply.started":"2024-01-07T13:38:47.201104Z","shell.execute_reply":"2024-01-07T13:38:47.205417Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def Model():\n    clf = MultinomialNB(alpha=0.02)\n#     clf2 = MultinomialNB(alpha=0.01)\n    sgd_model = SGDClassifier(max_iter=8000, tol=1e-4, loss=\"modified_huber\") \n    p6 = {\n        'n_iter': 1500,\n        'verbose': -1,\n        'objective': 'binary',\n        'metric': 'auc',\n        'learning_rate': 0.05073909898961407,\n        'colsample_bytree': 0.726023996436955,\n        'colsample_bynode': 0.5803681307354022,\n        'lambda_l1': 8.562963348932286,\n        'lambda_l2': 4.893256185259296,\n        'min_data_in_leaf': 115,\n        'max_depth': 23,\n        'max_bin': 898\n    }\n    lgb = LGBMClassifier(**p6)\n    cat = CatBoostClassifier(\n        iterations=1000,\n        verbose=0,\n        l2_leaf_reg=6.6591278779517808,\n        learning_rate=0.005689066836106983/2,\n        allow_const_label=True,\n        loss_function = 'CrossEntropy',\n        random_seed=1234\n    )\n    weights = [0.07,0.41,0.41,0.41]\n \n    ensemble = VotingClassifier(\n        estimators=[\n            ('mnb',clf),\n            ('sgd', sgd_model),\n            ('lgb',lgb), \n            ('cat', cat)\n        ],\n        weights=weights, voting='soft', n_jobs=-1\n    )\n    return ensemble","metadata":{"execution":{"iopub.status.busy":"2024-01-07T13:38:47.208167Z","iopub.execute_input":"2024-01-07T13:38:47.209087Z","iopub.status.idle":"2024-01-07T13:38:47.226056Z","shell.execute_reply.started":"2024-01-07T13:38:47.209046Z","shell.execute_reply":"2024-01-07T13:38:47.224149Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(Model())","metadata":{"execution":{"iopub.status.busy":"2024-01-07T13:49:16.10728Z","iopub.execute_input":"2024-01-07T13:49:16.107804Z","iopub.status.idle":"2024-01-07T13:49:16.129194Z","shell.execute_reply.started":"2024-01-07T13:49:16.107767Z","shell.execute_reply":"2024-01-07T13:49:16.127923Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if len(test.text.values) <= 5:\n    sub.to_csv('submission.csv', index=False)\nelse:\n    ensemble = Model()\n    ensemble.fit(tf_train, y_train)\n    gc.collect()\n    final_preds = ensemble.predict_proba(tf_test)[:,1]","metadata":{"execution":{"iopub.status.busy":"2024-01-07T13:38:47.231995Z","iopub.execute_input":"2024-01-07T13:38:47.232448Z","iopub.status.idle":"2024-01-07T13:38:47.253484Z","shell.execute_reply.started":"2024-01-07T13:38:47.232415Z","shell.execute_reply":"2024-01-07T13:38:47.25242Z"},"trusted":true},"execution_count":null,"outputs":[]}]}